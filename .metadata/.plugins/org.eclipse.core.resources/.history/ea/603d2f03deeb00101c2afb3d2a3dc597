package com.keeplynk.ai.llm;

import java.util.List;
import java.util.Map;

import org.springframework.beans.factory.annotation.Value;
import org.springframework.http.HttpEntity;
import org.springframework.http.HttpHeaders;
import org.springframework.http.MediaType;
import org.springframework.http.ResponseEntity;
import org.springframework.stereotype.Component;
import org.springframework.web.client.RestTemplate;

@Component
public class GroqLlmClient implements LlmClient {

    @Value("${groq.api.key}")
    private String apiKey;

    private static final String GROQ_ENDPOINT = "https://api.groq.com/openai/v1/chat/completions";
    
    private final RestTemplate restTemplate = new RestTemplate();

    @Override
    public String generate(String prompt) {
        HttpHeaders headers = new HttpHeaders();
        headers.setBearerAuth(apiKey);
        headers.setContentType(MediaType.APPLICATION_JSON);

        Map<String, Object> body = Map.of(
            "model", "llama-3.3-70b-versatile",
            "messages", List.of(
                Map.of(
                    "role", "user",
                    "content", prompt
                )
            ),
            "temperature", 0.7,
            "max_tokens", 500
        );

        HttpEntity<Map<String, Object>> request = new HttpEntity<>(body, headers);

        try {
            ResponseEntity<Map> response = 
                restTemplate.postForEntity(GROQ_ENDPOINT, request, Map.class);

            Map<String, Object> responseBody = response.getBody();
            
            List<Map<String, Object>> choices = (List<Map<String, Object>>) responseBody.get("choices");
            Map<String, Object> firstChoice = choices.get(0);
            Map<String, Object> message = (Map<String, Object>) firstChoice.get("message");
            
            return message.get("content").toString();

        } catch (Exception e) {
            e.printStackTrace();
            return "AI generation failed (Groq)";
        }
    }
}
